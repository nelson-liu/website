<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Hi, this is Nelson. Please DELETE the <script> block below (L6-L13)
          if you use this HTML, otherwise my analytics will track your page. -->
	    <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-51640218-1', 'auto');
            ga('send', 'pageview');
        </script>
        <title>Nelson F. Liu</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="http://nelsonliu.me" />
	    <meta property="og:title" content="Nelson F. Liu" />
	    <meta property="og:image" content="http://nelsonliu.me/img/nelson-liu-2018.jpg" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Nelson F. Liu">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="shortcut icon" type="image/png" href="favicon.ico"/>

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Nelson F. Liu</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 col-md-6 order-0 order-xs-0 order-sm-0 order-md-1 order-lg-1">
                    <div class="card mb-3">
                        <img class="card-img-top" src="img/nelson-liu-2018.jpg" alt="Nelson Liu">
                        <div class="card-body">
                            <h5 class="card-title">
                                <b>Nelson F. Liu</b>
                            </h5>
                            <p class="card-text">
                                PhD Student
                                </br>
                                Computer Science Department
                                </br>
                                Stanford University
                                </br>
                                </br>
                                Office: Gates 252
                                </br>
                                pronouns: he/him
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-6 order-1 order-xs-1 order-sm-1 order-md-0 order-lg-0">
                    <p>
                        Hi! I'm a first-year PhD student in computer science at
                        Stanford University, where I work in
                        the <a href="https://nlp.stanford.edu/"
                        target="_blank">Natural Language Processing Group</a>.
                    </p>
                    <p>
                        My research focuses on understanding and augmenting the
                        generalizability and robustness of natural language
                        processing systems. In general, I am interested in
                        bridging the gap between solving individual NLP
                        benchmarks and solving broader NLP tasks. My research is
                        graciously supported by a
                        <a href="https://www.nsfgrfp.org/general_resources/about"
                        target="_blank">NSF Graduate Research Fellowship</a>.
                    </p>
                    <p>
                        Previously, I spent four amazing years as an
                        undergraduate at the University of Washington, where I
                        worked with <a href="http://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>.
                        I've also spent time at the <a href="http://allenai.org/" target="_blank">Allen Institute for
                        Artificial Intelligence (AI2)</a> (working with <a href="http://matt-gardner.github.io/" target="_blank">Matt Gardner</a>),
                        and the <a href="http://www.isi.edu" target="_blank">USC Information
                        Sciences Institute</a> (working with <a href="http://www.isi.edu/~knight/" target="_blank">Kevin Knight</a> and
                        <a href="http://www.isi.edu/~jonmay/" target="_blank">Jonathan May</a>).
                    </p>
                    <p>
                        Thanks to the support of my research mentors, I was
                        fortunate to begin working on research early in my
                        undergraduate career. I’m happy to help ambitious
                        undergraduate students interested in natural language
                        processing or machine learning get started with
                        research—please feel free to email me!
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <p>
                        Email: nfliu [<a href="https://en.wikipedia.org/wiki/At_sign" target="_blank">strudel</a>] cs.stanford.edu
                    </p>
                    <p>
                        Links:
                        [<a href="files/N_LIU_CV.pdf" target="_blank">Full CV</a>] [<a href="https://twitter.com/nelsonfliu" target="_blank">Twitter</a>] [<a href="https://github.com/nelson-liu" target="_blank">Github</a>] [<a href="https://scholar.google.com/citations?user=ghGDz7MAAAAJ&hl=en" target="_blank">Google Scholar</a>] [<a href="https://blog.nelsonliu.me/" target="_blank">Blog</a>]
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h2>Recent News</h2>
                    <ul>
                        <li>
                            (8/2019) Paper on Quoref, a new reading
                            comprehension dataset with questions that require
                            resolving coreference, accepted to EMNLP 2019.
                        </li>
                        <li>
                            (8/2019) I'm participating in
                            the <a href="https://cbmm.mit.edu/"
                            target="_blank">Center for Brains, Minds, and
                            Machines'</a> <a href="https://cbmm.mit.edu/summer-school/2019"
                            target="_blank">summer course</a>.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Publications</h2>
                    <h3>2019</h3>
                    <ul class="pl">
                        <li>
                            <a href="papers/dasigi+liu+marasovic+smith+gardner.emnlp2019.pdf" target="_blank">
                                <b>Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning</b>
                            </a>
                            <br/>
                            <a href="http://www.cs.cmu.edu/~pdasigi/" target="_blank">Pradeep Dasigi</a>,
                            <b>Nelson F. Liu</b>,
                            <a href="https://amarasovic.github.io/" target="_blank">Ana Marasović</a>,
                            <a href="https://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>,
                            and <a href="https://matt-gardner.github.io/" target="_blank">Matt Gardner</a>.
                            <br/>
                            In <a href="https://www.emnlp-ijcnlp2019.org" target="_blank">
                                <b>
                                    Conference on Empirical Methods in Natural Language Processing &
                                    International Joint Conference on Natural Language Processing
                                    (EMNLP-IJCNLP)</b></a>, 2019.
                            <br/>
                            [<a href="papers/dasigi+liu+marasovic+smith+gardner.emnlp2019.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#dasigi_liu_marasovic_smith_gardner_emnlp2019_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/dasigi+liu+marasovic+smith+gardner.emnlp2019.poster.pdf" target="_blank">poster</a>]
                            [<a href="https://quoref-dataset.s3-us-west-2.amazonaws.com/train_and_dev/quoref-train-dev-v0.1.zip" target="_blank">dataset</a>]
                            [<a href="https://leaderboard.allenai.org/quoref" target="_blank">leaderboard</a>]
                            <div id="dasigi_liu_marasovic_smith_gardner_emnlp2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Machine comprehension of texts longer than a
                                    single sentence often requires coreference
                                    resolution. However, most current reading
                                    comprehension benchmarks do not contain
                                    complex coreferential phenomena and hence
                                    fail to evaluate the ability of models to
                                    resolve coreference. We present a new
                                    crowdsourced dataset containing more than
                                    24K span-selection questions that require
                                    resolving coreference among entities in
                                    over 4.7K English paragraphs from Wikipedia.
                                    Obtaining questions focused on such
                                    phenomena is challenging, because it is hard
                                    to avoid lexical cues that shortcut
                                    complex reasoning. We deal with this issue
                                    by using a strong baseline model as an
                                    adversary in the crowdsourcing loop, which
                                    helps crowdworkers avoid writing questions
                                    with exploitable surface cues. We show that
                                    state-of-the-art reading comprehension
                                    models perform significantly worse than
                                    humans on this benchmark—the best model
                                    performance is 70.5 F1, while the estimated
                                    human performance is 93.4 F1.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/logan+liu+peters+gardner+singh.acl2019.pdf" target="_blank">
                                <b>Barack's Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling</b>
                            </a>
                            <br/>
                            <a href="https://rloganiv.github.io/" target="_blank">Robert L. Logan IV</a>,
                            <b>Nelson F. Liu</b>,
                            <a href="http://matt-peters.github.io/" target="_blank">Matthew E. Peters</a>,
                            <a href="https://matt-gardner.github.io/" target="_blank">Matt Gardner</a>,
                            and <a href="http://sameersingh.org/" target="_blank">Sameer Singh</a>.
                            <br/>
                            In <a href="http://www.acl2019.org/" target="_blank">
                                <b>Annual Meeting of the Association for Computational Linguistics (ACL)</b></a>, 2019.
                            <br/>
                            [<a href="papers/logan+liu+peters+gardner+singh.acl2019.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#logan_liu_peters_gardner_singh_acl2019_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/logan+liu+peters+gardner+singh.acl2019.poster.pdf" target="_blank">poster</a>]
                            [<a href="https://github.com/rloganiv/kglm-model" target="_blank">code</a>]
                            [<a href="https://rloganiv.github.io/linked-wikitext-2/" target="_blank">dataset</a>]
                            <div id="logan_liu_peters_gardner_singh_acl2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Modeling human language requires the ability
                                    to not only generate fluent text but also
                                    encode factual knowledge. However,
                                    traditional language models are only capable
                                    of remembering facts seen at training time,
                                    and often have difficulty recalling them. To
                                    address this, we introduce the knowledge
                                    graph language model (KGLM), a neural
                                    language model with mechanisms for selecting
                                    and copying facts from a knowledge graph
                                    that are relevant to the context. These
                                    mechanisms enable the model to render
                                    information it has never seen before, as
                                    well as generate out-of-vocabulary tokens.
                                    We also introduce the Linked WikiText-2
                                    dataset, a corpus of annotated text aligned
                                    to the Wikidata knowledge graph whose
                                    contents (roughly) match the popular
                                    WikiText-2 benchmark (Merity et al., 2017).
                                    In experiments, we demonstrate that the KGLM
                                    achieves significantly better performance
                                    than a strong baseline language model. We
                                    additionally compare different language
                                    models’ ability to complete sentences
                                    requiring factual knowledge, and show that
                                    the KGLM outperforms even very large
                                    language models in generating facts.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/liu+gardner+belinkov+peters+smith.naacl2019.pdf" target="_blank">
                                <b>Linguistic Knowledge and Transferability of Contextual Representations</b>
                            </a>
                            <br/>
                            <b>Nelson F. Liu</b>,
                            <a href="https://matt-gardner.github.io/" target="_blank">Matt Gardner</a>,
                            <a href="http://people.csail.mit.edu/belinkov/" target="_blank">Yonatan Belinkov</a>,
                            <a href="http://matt-peters.github.io/" target="_blank">Matthew E. Peters</a>,
                            and <a href="https://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>.
                            <br/>
                            In <a href="https://naacl2019.org/" target="_blank">
                                <b>North American Chapter of the Association for Computational Linguistics (NAACL)</b></a>, 2019.
                            <br/>
                            [<a href="papers/liu+gardner+belinkov+peters+smith.naacl2019.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#liu_gardner_belinkov_peters_smith_naacl2019_abstract').toggle();return false;">abstract</a>]
                            [slides:
                            <a href="papers/liu+gardner+belinkov+peters+smith.naacl2019.slides.pdf" target="_blank">pdf</a>,
                            <a href="papers/liu+gardner+belinkov+peters+smith.naacl2019.slides.with_speaker_notes.pdf" target="_blank">pdf with notes</a>,
                            <a href="papers/liu+gardner+belinkov+peters+smith.naacl2019.slides.key" target="_blank">key</a>]
                            [<a href="papers/contextual-repr-analysis" target="_blank">code</a>]
                            <div id="liu_gardner_belinkov_peters_smith_naacl2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Contextual word representations derived from
                                    large-scale neural language models are
                                    successful across a diverse set of NLP
                                    tasks, suggesting that they encode useful
                                    and transferable features of language. To
                                    shed light on the linguistic knowledge they
                                    capture, we study the representations
                                    produced by several recent pretrained
                                    contextualizers (variants of ELMo, the
                                    OpenAI transformer LM, and BERT) with a
                                    suite of seventeen diverse probing tasks. We
                                    find that linear models trained on top of
                                    frozen contextual representations are
                                    competitive with state-of-the-art
                                    task-specific models in many cases, but fail
                                    on tasks requiring fine-grained linguistic
                                    knowledge (e.g., conjunct identification).
                                    To investigate the transferability of
                                    contextual word representations, we quantify
                                    differences in the transferability of
                                    individual layers within contextualizers,
                                    especially between RNNs and transformers.
                                    For instance, higher layers of RNNs are more
                                    task-specific, while transformer layers do
                                    not exhibit the same monotonic trend. In
                                    addition, to better understand what makes
                                    contextual word representations
                                    transferable, we compare language model
                                    pretraining with eleven supervised
                                    pretraining tasks. For any given task,
                                    pretraining on a closely related task yields
                                    better performance than language model
                                    pretraining (which is better on average)
                                    when the pretraining dataset is fixed.
                                    However, language model pretraining on more
                                    data gives the best results.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/liu+schwartz+smith.naacl2019.pdf" target="_blank">
                                <b>Inoculation by Fine-Tuning: A Method for Analyzing Challenge Datasets</b>
                            </a>
                            <br/>
                            <b>Nelson F. Liu</b>,
                            <a href="https://homes.cs.washington.edu/~roysch/" target="_blank">Roy Schwartz</a>,
                            and <a href="https://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>.
                            <br/>
                            In <a href="https://naacl2019.org/" target="_blank">
                                <b>North American Chapter of the Association for Computational Linguistics (NAACL)</b></a>, 2019.
                            <br/>
                            [<a href="papers/liu+schwartz+smith.naacl2019.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#liu_schwartz_smith_naacl2019_abstract').toggle();return false;">abstract</a>]
                            [slides:
                            <a href="papers/liu+schwartz+smith.naacl2019.slides.pdf" target="_blank">pdf</a>,
                            <a href="papers/liu+schwartz+smith.naacl2019.slides.with_speaker_notes.pdf" target="_blank">pdf with notes</a>,
                            <a href="papers/liu+schwartz+smith.naacl2019.slides.key" target="_blank">key</a>]
                            [<a href="papers/inoculation-by-finetuning" target="_blank">code</a>]
                            <div id="liu_schwartz_smith_naacl2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Several datasets have recently been
                                    constructed to expose brittleness in models
                                    trained on existing benchmarks. While model
                                    performance on these challenge datasets is
                                    significantly lower compared to the original
                                    benchmark, it is unclear what particular
                                    weaknesses they reveal. For example, a
                                    challenge dataset may be difficult because
                                    it targets phenomena that current models
                                    cannot capture, or because it simply
                                    exploits blind spots in a model's specific
                                    training set. We introduce inoculation by
                                    fine-tuning, a new analysis method for
                                    studying challenge datasets by exposing
                                    models (the metaphorical patient) to a small
                                    amount of data from the challenge dataset (a
                                    metaphorical pathogen) and assessing how
                                    well they can adapt. We apply our method to
                                    analyze the NLI "stress tests" (Naik et al.,
                                    2018) and the Adversarial SQuAD dataset (Jia
                                    and Liang, 2017). We show that after slight
                                    exposure, some of these datasets are no
                                    longer challenging, while others remain
                                    difficult. Our results indicate that
                                    failures on challenge datasets may lead to
                                    very different conclusions about models,
                                    training datasets, and the challenge
                                    datasets themselves.
                                </p>
                            </div>
                        </li>
                    </ul>
                    <h3>2018</h3>
                    <ul class="pl">
                        <li>
                            <a href="papers/liu+levy+schwartz+tan+smith.repl4nlp2018.pdf" target="_blank">
                                <b>LSTMs Exploit Linguistic Attributes of Data</b>
                            </a>
                            <br/>
                            <b>Nelson F. Liu</b>,
                            <a href="https://levyomer.wordpress.com/" target="_blank">Omer Levy</a>,
                            <a href="https://homes.cs.washington.edu/~roysch/" target="_blank">Roy Schwartz</a>,
                            <a href="https://chenhaot.com/" target="_blank">Chenhao Tan</a>,
                            and <a href="https://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>.
                            <br/>
                            In <a href="https://sites.google.com/site/repl4nlp2018" target="_blank">
                                <b>ACL Workshop on Representation Learning for NLP (RepL4NLP)</b></a>, 2018.
                            <b><a href="https://sites.google.com/site/repl4nlp2018/accepted-papers" target="_blank" style="color:#e22222">(Best Paper Award)</a></b>.
                            <br/>
                            [<a href="papers/liu+levy+schwartz+tan+smith.repl4nlp2018.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#liu_levy_schwartz_tan_smith_repl4nlp2018_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/liu+levy+schwartz+tan+smith.repl4nlp2018.slides.pdf" target="_blank">(short) slides</a>]
                            [<a href="papers/liu+levy+schwartz+tan+smith.repl4nlp2018.poster.pdf" target="_blank">poster</a>]
                            [<a href="papers/lstms-exploit-linguistic-attributes" target="_blank">code</a>]
                            <div id="liu_levy_schwartz_tan_smith_repl4nlp2018_abstract" class="abstract" style="display:none;">
                                <p>
                                    While recurrent neural networks have found
                                    success in a variety of natural language
                                    processing applications, they are general
                                    models of sequential data. We investigate
                                    how the properties of natural language data
                                    affect an LSTM's ability to learn a
                                    nonlinguistic task: recalling elements from
                                    its input. We find that models trained on
                                    natural language data are able to recall
                                    tokens from much longer sequences than
                                    models trained on non-language sequential
                                    data. Furthermore, we show that the LSTM
                                    learns to solve the memorization task by
                                    explicitly using a subset of its neurons to
                                    count timesteps in the input. We hypothesize
                                    that the patterns and structure in natural
                                    language data enable LSTMs to learn by
                                    providing approximate ways of reducing loss,
                                    but understanding the effect of different
                                    training data on the learnability of LSTMs
                                    remains an open question.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/allennlp.nlposs2018.pdf" target="_blank">
                                <b>AllenNLP: A Deep Semantic Natural Language Processing Platform</b>
                            </a>
                            <br/>
                            <a href="https://matt-gardner.github.io/" target="_blank">Matt Gardner</a>,
                            <a href="http://joelgrus.com/" target="_blank">Joel Grus</a>,
                            <a href="http://markneumann.xyz/" target="_blank">Mark Neumann</a>,
                            <a href="https://allenai.org/team/oyvindt/" target="_blank">Oyvind Tafjord</a>,
                            <a href="http://www.cs.cmu.edu/~pdasigi/" target="_blank">Pradeep Dasigi</a>,
                            <b>Nelson F. Liu</b>,
                            <a href="http://matt-peters.github.io/" target="_blank">Matthew Peters</a>,
                            <a href="https://schmitztech.com/" target="_blank">Michael Schmitz</a>,
                            and <a href="https://www.cs.washington.edu/people/faculty/lsz/" target="_blank">Luke Zettlemoyer</a>.
                            <br/>
                            In <a href="https://nlposs.github.io/" target="_blank">
                                <b>ACL Workshop for Natural Language Processing Open Source Software (NLP-OSS)</b></a>, 2018.
                            <br/>
                            [<a href="papers/allennlp.nlposs2018.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#allennlp_nlposs2018_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://github.com/allenai/allennlp" target="_blank">code</a>]
                            <div id="allennlp_nlposs2018_abstract" class="abstract" style="display:none;">
                                <p>
                                    This paper describes AllenNLP, a platform
                                    for research on deep learning methods in
                                    natural language understanding. AllenNLP is
                                    designed to support researchers who want to
                                    build novel language understanding models
                                    quickly and easily. It is built on top of
                                    PyTorch, allowing for dynamic computation
                                    graphs, and provides (1) a flexible data API
                                    that handles intelligent batching and
                                    padding, (2) high-level abstractions for
                                    common operations in working with text, and
                                    (3) a modular and extensible experiment
                                    framework that makes doing good science
                                    easy. It also includes reference
                                    implementations of high quality approaches
                                    for both core semantic problems (e.g.
                                    semantic role labeling (Palmer et al.,
                                    2005)) and language understanding
                                    applications (e.g. machine comprehension
                                    (Rajpurkar et al., 2016)). AllenNLP is an
                                    ongoing open-source effort maintained by
                                    engineers and researchers at the Allen
                                    Institute for Artificial Intelligence.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/liu+levow+smith.sclem2018.pdf" target="_blank">
                                <b>Discovering Phonesthemes with Sparse Regularization</b>
                            </a>
                            <br/>
                            <b>Nelson F. Liu</b>,
                            <a href="https://faculty.washington.edu/levow/" target="_blank">Gina-Anne Levow</a>,
                            and <a href="https://homes.cs.washington.edu/~nasmith/" target="_blank">Noah A. Smith</a>.
                            <br/>
                            In <a href="https://sites.google.com/view/sclem2018/" target="_blank">
                                <b>NAACL Workshop on Subword and Character Level Models in NLP (SCLeM)</b></a>, 2018.
                            <br/>
                            [<a href="papers/liu+levow+smith.sclem2018.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#liu_levow_smith_sclem2018_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/liu+levow+smith.sclem2018.poster.pdf" target="_blank">poster</a>]
                            [<a href="papers/phonesthemes" target="_blank">code</a>]
                            <div id="liu_levow_smith_sclem2018_abstract" class="abstract" style="display:none;">
                                <p>
                                    We introduce a simple method for extracting
                                    non-arbitrary form-meaning representations
                                    from a collection of semantic vectors. We
                                    treat the problem as one of feature
                                    selection for a model trained to predict
                                    word vectors from subword features. We apply
                                    this model to the problem of automatically
                                    discovering phonesthemes, which are
                                    submorphemic sound clusters that appear in
                                    words with similar meaning. Many of our
                                    model-predicted phonesthemes overlap with
                                    those proposed in the linguistics
                                    literature, and we validate our approach
                                    with human judgments.
                                </p>
                            </div>
                        </li>
                    </ul>
                    <h3>2017</h3>
                    <ul class="pl">
                        <li>
                            <a href="papers/welbl+liu+gardner.wnut2017.pdf" target="_blank">
                                <b>Crowdsourcing Multiple Choice Science Questions</b>
                            </a>
                            <br/>
                            <a href="https://jowel.gitlab.io/welbl/" target="_blank">Johannes Welbl</a>,
                            <b>Nelson F. Liu</b>,
                            and <a href="https://matt-gardner.github.io/" target="_blank">Matt Gardner</a>.
                            <br/>
                            In <a href="http://noisy-text.github.io/2017" target="_blank">
                                <b>EMNLP Workshop on Noisy User-generated Text</b></a>, 2017.
                            <br/>
                            [<a href="papers/welbl+liu+gardner.wnut2017.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#welbl_liu_gardner_wnut2017_abstract').toggle();return false;">abstract</a>]
                            [<a href="http://data.allenai.org/sciq/" target="_blank">data</a>]
                            [<a href="papers/sciq/welbl+liu+gardner.wnut2017.poster.pdf" target="_blank">poster</a>]
                            <div id="welbl_liu_gardner_wnut2017_abstract" class="abstract" style="display:none;">
                                <p>
                                    We present a novel method for obtaining
                                    high-quality, domain-targeted multiple
                                    choice questions from crowd workers.
                                    Generating these questions can be difficult
                                    without trading away originality, relevance
                                    or diversity in the answer options. Our
                                    method addresses these problems by
                                    leveraging a large corpus of domain-specific
                                    text and a small set of existing questions.
                                    It produces model suggestions for document
                                    selection and answer distractor choice which
                                    aid the human question generation process.
                                    With this method we have assembled SciQ, a
                                    dataset of 13.7K multiple choice science
                                    exam questions (Dataset available
                                    at <a href="http://data.allenai.org/sciq/"
                                    target="_blank">data.allenai.org/sciq/</a>).
                                    We demonstrate that the method produces
                                    in-domain questions by providing an analysis
                                    of this new dataset and by showing that
                                    humans cannot distinguish the crowdsourced
                                    questions from original questions. When
                                    using SciQ as additional training data to
                                    existing questions, we observe accuracy
                                    improvements on real science exams.
                                </p>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
                        <li>
                            In my free time, I like to cycle (slowly) and climb
                            (indoors, poorly).
                        </li>
                        <li>
                            Feel free to
                            use <a href="https://github.com/nelson-liu/website"
                            target="_blank">this website's source code</a>, I'd
                            just appreciate if you linked back
                            to this page (<a href="https://nelsonliu.me/"
                            target="_blank">https://nelsonliu.me</a>).
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            © Nelson Liu, 2020
                        </p>
                    </div>
                    <div class="col-6 col-md text-right">
                        <a href="https://nlp.stanford.edu" class="image-link">
                            <img class="mr-4" src="img/stanford_nlp_logo.gif" alt="Stanford NLP Group logo." height="75">
                        </a>
                        <a href="http://ai.stanford.edu" class="image-link">
                            <img src="img/stanford_ai_logo.jpg" alt="Stanford AI Lab logo." height="75">
                        </a>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
